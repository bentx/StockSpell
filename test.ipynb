{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pytz\n",
    "from pytz import timezone\n",
    "from pydantic import BaseModel\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import requests\n",
    "from pushbullet import Pushbullet\n",
    "import pandas as pd\n",
    "from csv import writer\n",
    "import stockFormula\n",
    "import talib\n",
    "import pandas_ta as ta\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RSI(df):\n",
    "    close = df['close']\n",
    "    rsi = talib.RSI(close, timeperiod=14)\n",
    "    rsi2 = talib.RSI(close, timeperiod=14)\n",
    "    df['rsi'] = rsi\n",
    "    df['rsi2'] = rsi2\n",
    "    return df\n",
    "\n",
    "     \n",
    "def RSIMovingAverage(list,index,divident):\n",
    "    data = list[:index+1]\n",
    "    data = data[-divident:]\n",
    "    sum=0.00\n",
    "    for i in data:\n",
    "        sum=sum+ RSI(list,list.index(i),divident)\n",
    "    return(sum/divident)\n",
    "\n",
    "def MovingAverage(df):\n",
    "    df['MA200'] = df['close'].rolling(200).mean()\n",
    "    df['MA100'] = df['close'].rolling(100).mean()\n",
    "    df['MA50'] = df['close'].rolling(50).mean()\n",
    "    df['MA20'] = df['close'].rolling(20).mean()\n",
    "    df['MA14'] = df['close'].rolling(14).mean()\n",
    "    df['MA5'] = df['close'].rolling(5).mean()\n",
    "    return df\n",
    "\n",
    "def AverageVolume(df) :\n",
    "    df['av']  = df['volume'].rolling(30).mean()\n",
    "    return df\n",
    "       \n",
    "def hikendataconvertion(data):\n",
    "    hikendata =  data.copy()\n",
    "    for i in data[1:] :\n",
    "         prevdata=hikendata[data.index(i)-1].split(\",\")\n",
    "         arrdata=data[data.index(i)].split(\",\")\n",
    "         HAopen=round(((float(prevdata[1]) + float(prevdata[4]))/2),2)\n",
    "         HAclose=round(((float(arrdata[1])+float(arrdata[4])+float(arrdata[2])+float(arrdata[3]))/4),2)\n",
    "         testdata=arrdata[0]+\",\"+str(round(((float(prevdata[1]) + float(prevdata[4]))/2),2))+\",\"+str(max(HAopen,HAclose,float(arrdata[2])))+\",\"+str(min(HAopen,HAclose,float(arrdata[3])))+\",\"+str(round(((float(arrdata[1])+float(arrdata[4])+float(arrdata[2])+float(arrdata[3]))/4),2))+\",\"+arrdata[5]\n",
    "         hikendata[data.index(i)]=testdata\n",
    "    return hikendata\n",
    "\n",
    "def convertToDF(data):\n",
    "    return  pd.DataFrame({\n",
    "                    'date':data[\"t\"],\n",
    "                    'open': data[\"o\"],\n",
    "                    'high': data[\"h\"],\n",
    "                    'low':data[\"l\"],\n",
    "                    'close':data[\"c\"],\n",
    "                    'volume':data[\"v\"]})\n",
    "                    \n",
    "def VWMA(df):\n",
    "    df['vwma'] = df.ta.vwma(length = 20,fillna=True)\n",
    "    return df\n",
    "\n",
    "def VA(df,type):\n",
    "    if type==\"1WVA\":\n",
    "         df['1WVA'] = df['volume'].rolling(5).mean()\n",
    "    return df\n",
    "        \n",
    "\n",
    "    \n",
    "def MACD(df):\n",
    "    # Get the 26-day EMA of the closing price\n",
    "    k = df['close'].ewm(span=12, adjust=False, min_periods=12).mean()\n",
    "    # Get the 12-day EMA of the closing price\n",
    "    d = df['close'].ewm(span=26, adjust=False, min_periods=26).mean()\n",
    "    # Subtract the 26-day EMA from the 12-Day EMA to get the MACD\n",
    "    macd = k - d\n",
    "    # Get the 9-Day EMA of the MACD for the Trigger line\n",
    "    macd_s = macd.ewm(span=9, adjust=False, min_periods=9).mean()\n",
    "    # Calculate the difference between the MACD - Trigger for the Convergence/Divergence value\n",
    "    macd_h = macd - macd_s\n",
    "    # Add all of our new values for the MACD to the dataframe\n",
    "    df['macd'] = df.index.map(macd)\n",
    "    df['macd_h'] = df.index.map(macd_h)\n",
    "    df['macd_s'] = df.index.map(macd_s)\n",
    "\n",
    "    return df\n",
    "\n",
    "# responseday = requests.get(\"https://api.upstox.com/historical/NSE_EQ/1660/day?timestamp=\")\n",
    "# data=responseday.json()['data']\n",
    "# print(data.index(data[-1]))\n",
    "# index=data.index(data[-4])\n",
    "# print (data[index])\n",
    "# hikendata=hikendataconvertion(data)\n",
    "# MovingAverage(hikendata,index,50)todate = datetime.today()\n",
    "def heikin_ashi(df):\n",
    "    heikin_ashi_df = pd.DataFrame(index=df.index.values, columns=['open', 'high', 'low', 'close'])\n",
    "    \n",
    "    heikin_ashi_df['close'] = (df['open'] + df['high'] + df['low'] + df['close']) / 4\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if i == 0:\n",
    "            heikin_ashi_df.iat[0, 0] = df['open'].iloc[0]\n",
    "        else:\n",
    "            heikin_ashi_df.iat[i, 0] = (heikin_ashi_df.iat[i-1, 0] + heikin_ashi_df.iat[i-1, 3]) / 2\n",
    "        \n",
    "    heikin_ashi_df['high'] = heikin_ashi_df.loc[:, ['open', 'close']].join(df['high']).max(axis=1)\n",
    "    \n",
    "    heikin_ashi_df['low'] = heikin_ashi_df.loc[:, ['open', 'close']].join(df['low']).min(axis=1)\n",
    "    heikin_ashi_df['volume']=df['volume']\n",
    "    heikin_ashi_df['date']=df['date']\n",
    "\n",
    "    return heikin_ashi_df\n",
    "\n",
    "\n",
    "def bollinger_bands(df):\n",
    "    currunt_upper_bollinger_band = ta.bbands(df[\"close\"], length=20, std=2)\n",
    "    df['up']=currunt_upper_bollinger_band[\"BBU_20_2.0\"]\n",
    "    df['down']=currunt_upper_bollinger_band[\"BBL_20_2.0\"]\n",
    "    df['middle']=currunt_upper_bollinger_band[\"BBM_20_2.0\"]\n",
    "    return df\n",
    "   \n",
    "def ADX(df):\n",
    "    df['adx']  = talib.ADX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    return df\n",
    "    \n",
    "def percentageCalc(num1,num2):\n",
    "    x=abs(num1-num2)\n",
    "    y=num1+num2\n",
    "    z=x/y\n",
    "    return z*100\n",
    "\n",
    "def findPercentage(num1,num2):\n",
    "    return int(num1)/int(num2)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getStockData(stockCode,timeList):\n",
    "    data=[]\n",
    "    for timeLine in timeList:\n",
    "        #todate = datetime.today()-timedelta(days=365)\n",
    "        todate = datetime.today()\n",
    "        fromdate = todate - timedelta(days=timeLine[1])\n",
    "        response = requests.get(\"https://priceapi.moneycontrol.com/techCharts/indianMarket/stock/history?symbol=\"+stockCode+\"&resolution=\"+timeLine[0]+\"&from=\"+str(int (time.mktime(fromdate.timetuple())))+\"&to=\"+str(int (time.mktime(todate.timetuple()))))\n",
    "        data.append([timeLine[0],response.json()])\n",
    "    return data\n",
    "    \n",
    "def getPreLoadedData(timeLine,stockCode):\n",
    "    print(\" processing from state\")\n",
    "    dfList=[]\n",
    "    ha_dfList=[]\n",
    "    for t in timeLine:\n",
    "        df = pd.read_pickle(\"./DFState/data\"+stockCode+t[0]+\".pkl\")\n",
    "        ha_df=pd.read_pickle(\"./DFState/HAdata\"+stockCode+t[0]+\".pkl\")\n",
    "        dfList.append(df.copy())\n",
    "        ha_dfList.append(ha_df.copy())\n",
    "    return [dfList,ha_dfList]\n",
    "\n",
    "\n",
    "def preProcess(dataList,stockCode):\n",
    "    dfList=[]\n",
    "    ha_dfList=[]\n",
    "    for data in dataList:\n",
    "        df=convertToDF(data[1])\n",
    "        df=MACD(df)\n",
    "        df=VWMA(df)\n",
    "        df=RSI(df)\n",
    "        df=VA(df,\"1WVA\")\n",
    "        df=bollinger_bands(df)\n",
    "        df=ADX(df)\n",
    "        df=MovingAverage(df)\n",
    "        df=AverageVolume(df)\n",
    "\n",
    "        #df.to_pickle(\"./DFState/data\"+stockCode+data[0]+\".pkl\")\n",
    "\n",
    "        #hiken\n",
    "        ha_df=heikin_ashi(df.copy())\n",
    "        ha_df=MACD(ha_df)\n",
    "        ha_df=VWMA(ha_df)\n",
    "        ha_df=RSI(ha_df)\n",
    "        ha_df=VA(ha_df,\"1WVA\")\n",
    "        ha_df=bollinger_bands(ha_df)\n",
    "        ha_df=ADX(ha_df)\n",
    "        ha_df=MovingAverage(ha_df)\n",
    "        ha_df=AverageVolume(ha_df)\n",
    "\n",
    "        #df.to_pickle(\"./DFState/HAdata\"+stockCode+data[0]+\".pkl\")\n",
    "        dfList.append(df.copy())\n",
    "        ha_dfList.append(ha_df.copy())\n",
    "        \n",
    "    return [dfList,ha_dfList]\n",
    "\n",
    "def storeInFile(fileName,data):\n",
    "    with open( fileName, 'a',newline='', encoding='utf-8') as object:\n",
    "                                writer_object = writer(object)\n",
    "                                writer_object.writerow(data)\n",
    "                                object.close()\n",
    "\n",
    "def calcWinWithPercentage(stratagy,overall,percentage):\n",
    "    total=0\n",
    "    win=0\n",
    "    totalAmount=0\n",
    "    winAmount=0\n",
    "    for result in overall[stratagy]:\n",
    "        total=total+1\n",
    "        previous =0\n",
    "        proceed=True\n",
    "        totalAmount=totalAmount+10000\n",
    "        #print(\"######################################\")\n",
    "        for i in range(6,15):\n",
    "            currentAmount=10000+((10000/result[5])*result[i])\n",
    "            #print(\"initial\"+str(result[i]))\n",
    "            if result[i]>0 and proceed:           \n",
    "                if i==14:\n",
    "                    #print(result[0]+\"finalLoop\"+str(result[i]))\n",
    "                    winAmount=winAmount+currentAmount\n",
    "                    #print(result[0]+\"finalLoop@#################################\"+str(winAmount))\n",
    "\n",
    "                else:\n",
    "                    current=percentageCalc(result[5],result[i]+result[5])             \n",
    "                    if currentAmount-10000>100:\n",
    "                        win=win+1\n",
    "                        #print(result[0]+\"possitive_Win\"+str(result[i]))\n",
    "                        winAmount=winAmount+currentAmount\n",
    "                        #print(result[0]+\"win_current_End@#################################\"+str(winAmount))\n",
    "\n",
    "                        proceed=False\n",
    "                    elif previous>current:\n",
    "                        #print(result[0]+\"negative_current\"+str(result[i]))\n",
    "                        winAmount=winAmount+currentAmount\n",
    "                        #print(result[0]+\"negative_current_End@#################################\"+str(winAmount))\n",
    "                        proceed=False\n",
    "                    previous=current\n",
    "            else:\n",
    "                if i==14 and  proceed:\n",
    "                    #print(result[0]+\"finalLoop_\"+str(result[i]))\n",
    "                    winAmount=winAmount+currentAmount\n",
    "                    #print(result[0]+\"finalLoop_@#################################\"+str(winAmount))\n",
    "\n",
    "                elif  proceed:\n",
    "                    #print(result[0]+\"negative_val\"+str(result[i]))\n",
    "                    winAmount=winAmount+currentAmount\n",
    "                    #print(result[0]+\"negative_val@#################################\"+str(winAmount))\n",
    "\n",
    "                break\n",
    "    return [total,win,totalAmount,winAmount]\n",
    "\n",
    "def findCandleType(df,index):\n",
    "    if ((df.loc[:, 'open'][index]<df.loc[:, 'close'][index])and(df.loc[:, 'open'][index]==df.loc[:, 'low'][index]) ):\n",
    "        return \"G\"\n",
    "    elif ((df.loc[:, 'open'][index]>df.loc[:, 'close'][index])and(df.loc[:, 'open'][index]==df.loc[:, 'high'][index]) ):\n",
    "        return \"R\"\n",
    "    elif ((df.loc[:, 'open'][index]<df.loc[:, 'close'][index]) ):\n",
    "        return \"G1\"\n",
    "    else:\n",
    "        return \"R1\"  \n",
    "\n",
    "def isTouchLow(df,index):\n",
    "    if((df.loc[:, 'close'][index]<df.loc[:, 'down'][index])):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def calcRealProfit(result,visited):\n",
    "     count =(10000/float(result[6]))\n",
    "     for i in range(7,16):\n",
    "        if(float(result[i])*count>100):\n",
    "            return True\n",
    "        else:\n",
    "            date=datetime.strptime(result[0], '%b %d %Y %I:%M%p')\n",
    "            date=date+timedelta(days=i-5)\n",
    "            visited.append(date.strftime(\"%b %d %Y %I:%M%p\"))\n",
    "     return False\n",
    "\n",
    "def calcRealProfitInIsolation(result,stockVisited):\n",
    "     count =(10000/float(result[6]))\n",
    "     for i in range(7,16):\n",
    "        if(float(result[i])*count>100):\n",
    "            return True\n",
    "        else:\n",
    "            date=datetime.strptime(result[0], '%b %d %Y %I:%M%p')\n",
    "            date=date+timedelta(days=i-5)\n",
    "            stockVisited[result[2]].append(date.strftime(\"%b %d %Y %I:%M%p\"))\n",
    "     return False\n",
    "\n",
    "def findRange(rangeList,val):\n",
    "    for i in rangeList:\n",
    "        if float(val)>float(i[0]) and float(val)<float(i[1]):\n",
    "            return str(i[0])+\"-\"+str(i[1])\n",
    "    return \"null\"    \n",
    "\n",
    "def FCTP(df,index):\n",
    "    if float(df.at[index, 'close']) > float(df.at[index, 'open']):\n",
    "        return \"G\"\n",
    "    else:\n",
    "        return \"R\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC Ltd\n",
      "Aegis Logistics Ltd\n",
      "Amrutanjan Health Care Ltd\n",
      "Andhra Paper Ltd\n",
      "Apollo Tyres Ltd\n",
      "Arvind Ltd\n",
      "Processed 7 lines.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('./Stocks/NSE_Test_Script_code.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0   \n",
    "    timeLine=[[\"1D\",665]]\n",
    "    rootdf = pd.DataFrame()\n",
    "    rootdfv = pd.DataFrame()\n",
    "    wvadf = pd.DataFrame()\n",
    "    adxdf = pd.DataFrame()\n",
    "    rsidf = pd.DataFrame()\n",
    "\n",
    "    stockRank=[]\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            print(row[1])\n",
    "            dataList=getStockData( row[0],timeLine)\n",
    "            #[dfList,ha_dfList]=getPreLoadedData(timeLine,row[0])\n",
    "            [dfList,ha_dfList]=preProcess(dataList, row[0])\n",
    "            dfList[0]['date'] = pd.to_datetime(dfList[0]['date'],unit='s')\n",
    "            df=dfList[0][['date','close']]\n",
    "            df=df.set_index('date')\n",
    "            df.rename(columns = {'close':row[0]}, inplace = True)\n",
    "            rootdf=pd.concat([rootdf, df], axis=1)\n",
    "\n",
    "            # response = requests.get(\"https://api.tickertape.in/search?text=\"+row[0]+\"&types=stock\")\n",
    "            # sid=response.json()[\"data\"][\"stocks\"][0][\"sid\"]\n",
    "            # #print(\"thirdtapi\")\n",
    "            # response = requests.get(\"https://api.tickertape.in/stocks/info/\"+sid)\n",
    "            # response=response.json()\n",
    "            # if(int(response[\"data\"][\"ratios\"][\"mrktCapRank\"])<100):\n",
    "            #     stockRank.append(row[0])\n",
    "\n",
    "\n",
    "\n",
    "            dfv=dfList[0][['date','volume']]\n",
    "            dfv=dfv.set_index('date')\n",
    "            dfv.rename(columns = {'volume':row[0]}, inplace = True)\n",
    "            rootdfv=pd.concat([rootdfv, dfv], axis=1)\n",
    "\n",
    "            wdf=dfList[0][['date','1WVA']]\n",
    "            wdf=wdf.set_index('date')\n",
    "            wdf.rename(columns = {'1WVA':row[0]}, inplace = True)\n",
    "            wvadf=pd.concat([wvadf, wdf], axis=1)\n",
    "\n",
    "            adf=dfList[0][['date','adx']]\n",
    "            adf=adf.set_index('date')\n",
    "            adf.rename(columns = {'adx':row[0]}, inplace = True)\n",
    "            adxdf=pd.concat([adxdf, adf], axis=1)\n",
    "\n",
    "            rdf=dfList[0][['date','rsi']]\n",
    "            rdf=rdf.set_index('date')\n",
    "            rdf.rename(columns = {'rsi':row[0]}, inplace = True)\n",
    "            rsidf=pd.concat([rsidf, rdf], axis=1)\n",
    "\n",
    "            line_count+= 1\n",
    "\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "             print(\"Oops!\", e, \"occurred.\")\n",
    "    line_count += 1\n",
    "    #rootdf['date'] = pd.to_datetime(rootdf['date'],unit='s')\n",
    "    #rootdf =rootdf.dropna(axis=1)\n",
    "    #mtl=(rootdf.pct_change()+1)[1:].resample('M').prod()\n",
    "    #ret12,ret6,ret3=getRolling(mtl,12),getRolling(mtl,6),getRolling(mtl,3)\n",
    "\n",
    "    print(f'Processed {line_count} lines.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>AEGISCHEM</th>\n",
       "      <th>AMRUTANJAN</th>\n",
       "      <th>ANDHRAPAP</th>\n",
       "      <th>APOLLOTYRE</th>\n",
       "      <th>ARVIND</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-22</th>\n",
       "      <td>1.078205</td>\n",
       "      <td>0.937042</td>\n",
       "      <td>1.059111</td>\n",
       "      <td>1.001734</td>\n",
       "      <td>0.985118</td>\n",
       "      <td>0.963388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-25</th>\n",
       "      <td>0.983987</td>\n",
       "      <td>1.065055</td>\n",
       "      <td>1.058447</td>\n",
       "      <td>0.989829</td>\n",
       "      <td>1.013980</td>\n",
       "      <td>0.985842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-28</th>\n",
       "      <td>1.006499</td>\n",
       "      <td>0.965454</td>\n",
       "      <td>0.984083</td>\n",
       "      <td>0.973983</td>\n",
       "      <td>0.991550</td>\n",
       "      <td>1.006047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-31</th>\n",
       "      <td>1.020971</td>\n",
       "      <td>1.041487</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>1.007407</td>\n",
       "      <td>1.058758</td>\n",
       "      <td>1.038317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-03</th>\n",
       "      <td>0.990096</td>\n",
       "      <td>0.956349</td>\n",
       "      <td>0.968039</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.939420</td>\n",
       "      <td>0.959479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>0.997447</td>\n",
       "      <td>0.987923</td>\n",
       "      <td>1.012900</td>\n",
       "      <td>1.003823</td>\n",
       "      <td>0.993262</td>\n",
       "      <td>1.019329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>0.986771</td>\n",
       "      <td>0.986481</td>\n",
       "      <td>1.014143</td>\n",
       "      <td>0.996191</td>\n",
       "      <td>0.986895</td>\n",
       "      <td>0.970441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>1.002760</td>\n",
       "      <td>0.996793</td>\n",
       "      <td>0.983140</td>\n",
       "      <td>0.994863</td>\n",
       "      <td>1.024059</td>\n",
       "      <td>0.993103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08</th>\n",
       "      <td>1.001242</td>\n",
       "      <td>1.045488</td>\n",
       "      <td>1.036768</td>\n",
       "      <td>0.979825</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>1.017361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-11</th>\n",
       "      <td>0.977449</td>\n",
       "      <td>0.995383</td>\n",
       "      <td>0.995507</td>\n",
       "      <td>1.008947</td>\n",
       "      <td>0.972691</td>\n",
       "      <td>1.015358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ACC  AEGISCHEM  AMRUTANJAN  ANDHRAPAP  APOLLOTYRE    ARVIND\n",
       "date                                                                        \n",
       "2021-03-22  1.078205   0.937042    1.059111   1.001734    0.985118  0.963388\n",
       "2021-03-25  0.983987   1.065055    1.058447   0.989829    1.013980  0.985842\n",
       "2021-03-28  1.006499   0.965454    0.984083   0.973983    0.991550  1.006047\n",
       "2021-03-31  1.020971   1.041487    1.040390   1.007407    1.058758  1.038317\n",
       "2021-04-03  0.990096   0.956349    0.968039   0.980392    0.939420  0.959479\n",
       "...              ...        ...         ...        ...         ...       ...\n",
       "2022-12-30  0.997447   0.987923    1.012900   1.003823    0.993262  1.019329\n",
       "2023-01-02  0.986771   0.986481    1.014143   0.996191    0.986895  0.970441\n",
       "2023-01-05  1.002760   0.996793    0.983140   0.994863    1.024059  0.993103\n",
       "2023-01-08  1.001242   1.045488    1.036768   0.979825    0.994355  1.017361\n",
       "2023-01-11  0.977449   0.995383    0.995507   1.008947    0.972691  1.015358\n",
       "\n",
       "[221 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootdf =rootdf.dropna(axis=1)\n",
    "#rootdf['date'] = pd.to_datetime(rootdf['date'],unit='s')\n",
    "rootdf\n",
    "mtl=(rootdf.pct_change()+1)[1:].resample('M').prod()\n",
    "mtlv=(rootdfv)[1:].resample('M').prod()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_rolling_ret(df,n):\n",
    "    return df.rolling(n).apply(np.prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_12,ret_6,ret_3 = get_rolling_ret(mtl,12),get_rolling_ret(mtl,6),get_rolling_ret(mtl,3)\n",
    "resv_12=get_rolling_ret(mtlv,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(date):    \n",
    "    top_50=ret_12.loc[date].nlargest(50).index\n",
    "    print(top_50)\n",
    "    top_30=ret_6.loc[date,top_50].nlargest(30).index\n",
    "    print(top_30)\n",
    "    top_10=ret_3.loc[date,top_30].nlargest(10).index\n",
    "    return top_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdf =rootdf.dropna(axis=1)\n",
    "mtl=(rootdf.pct_change()+1)[1:].resample('M').prod()\n",
    "\n",
    "ret_12,ret_6,ret_3 = get_rolling_ret(mtl,12),get_rolling_ret(mtl,6),get_rolling_ret(mtl,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "adx=adxdf.loc[\"2021-03-31\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-31 00:00:00\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "2021-04-30 00:00:00\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "2021-05-31 00:00:00\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "2021-06-30 00:00:00\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "2021-07-31 00:00:00\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Timestamp('2021-07-31 00:00:00', freq='M')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mpandas\\_libs\\index.pyx:444\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:1625\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:1632\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1627689600000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\91948\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3080\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3080\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3081\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas\\_libs\\index.pyx:413\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index.pyx:446\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: Timestamp('2021-07-31 00:00:00', freq='M')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\91948\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:686\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39;49mget_loc(\u001b[39mself\u001b[39;49m, key, method, tolerance)\n\u001b[0;32m    687\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\91948\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3082\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3081\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3082\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[39mif\u001b[39;00m tolerance \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: Timestamp('2021-07-31 00:00:00', freq='M')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(date)\n\u001b[0;32m      3\u001b[0m stock_list\u001b[39m=\u001b[39mget_top(date)\n\u001b[1;32m----> 4\u001b[0m adx\u001b[39m=\u001b[39madxdf\u001b[39m.\u001b[39;49mloc[date,stock_list]\n\u001b[0;32m      5\u001b[0m rsi\u001b[39m=\u001b[39mrsidf\u001b[39m.\u001b[39mloc[date,stock_list]\n\u001b[0;32m      6\u001b[0m wva\u001b[39m=\u001b[39mwvadf\u001b[39m.\u001b[39mloc[date,stock_list]\n",
      "File \u001b[1;32mc:\\Users\\91948\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:889\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[39mwith\u001b[39;00m suppress(\u001b[39mKeyError\u001b[39;00m, \u001b[39mIndexError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m):\n\u001b[0;32m    887\u001b[0m             \u001b[39m# AttributeError for IntervalTree get_value\u001b[39;00m\n\u001b[0;32m    888\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m--> 889\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m    890\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\91948\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1060\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1058\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getitem_tuple\u001b[39m(\u001b[39mself\u001b[39m, tup: Tuple):\n\u001b[0;32m   1059\u001b[0m     \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m-> 1060\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1062\u001b[0m     \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_tuple(tup)\n",
      "File \u001b[1;32mc:\\Users\\91948\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:807\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[39mfor\u001b[39;00m i, key \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tup):\n\u001b[0;32m    804\u001b[0m     \u001b[39mif\u001b[39;00m is_label_like(key):\n\u001b[0;32m    805\u001b[0m         \u001b[39m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[0;32m    806\u001b[0m         \u001b[39m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m         section \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    809\u001b[0m         \u001b[39m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[0;32m    810\u001b[0m         \u001b[39m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[0;32m    811\u001b[0m         \u001b[39m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m         \u001b[39mif\u001b[39;00m section\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[0;32m    813\u001b[0m             \u001b[39m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[0;32m    814\u001b[0m             \u001b[39m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91948\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1124\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1122\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1124\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\91948\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[0;32m   1072\u001b[0m     \u001b[39m# GH#5667 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1073\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\91948\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:3739\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3737\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected label or tuple of labels, got \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   3738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3739\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3741\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m   3742\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[1;32mc:\\Users\\91948\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:688\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    686\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39mget_loc(\u001b[39mself\u001b[39m, key, method, tolerance)\n\u001b[0;32m    687\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 688\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(orig_key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: Timestamp('2021-07-31 00:00:00', freq='M')"
     ]
    }
   ],
   "source": [
    "for  date in mtl.index[:-1]:\n",
    "        print(date)\n",
    "        stock_list=get_top(date)\n",
    "        adx=adxdf.loc[date,stock_list]\n",
    "        rsi=rsidf.loc[date,stock_list]\n",
    "        wva=wvadf.loc[date,stock_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ADANIPOWER', 'BANKBARODA', 'ADANIENT', 'VBL', 'HAL', 'UNIONBANK',\n",
       "       'CANBK', 'TIINDIA', 'IOB', 'COALINDIA', 'JINDALSTEL', 'ITC', 'YESBANK',\n",
       "       'ADANITRANS', 'ADANIGREEN', 'AMBUJACEM', 'AXISBANK', 'INDUSINDBK',\n",
       "       'NTPC', 'EICHERMOT', 'ABB', 'SIEMENS', 'BRITANNIA', 'SUNPHARMA',\n",
       "       'BHARTIARTL', 'IDBI', 'JSWSTEEL', 'CIPLA', 'ADANIPORTS', 'GAIL',\n",
       "       'HEROMOTOCO', 'HDFCBANK', 'HINDUNILVR', 'RAILTEL', 'RELIANCE', 'GRASIM',\n",
       "       'BAJAJHLDNG', 'POWERGRID', 'TATACONSUM', 'ONGC', 'SBILIFE', 'IOC',\n",
       "       'TATASTEEL', 'HINDALCO', 'INDIGO', 'NESTLEIND', 'MARICO', 'DABUR',\n",
       "       'DLF', 'SRF', 'TORNTPHARM', 'BAJAJFINSV', 'BAJFINANCE', 'TATAPOWER',\n",
       "       'ULTRACEMCO', 'ASIANPAINT', 'VEDL', 'GODREJCP', 'APOLLOHOSP', 'ICICIGI',\n",
       "       'HDFCLIFE', 'TCS', 'DMART', 'DRREDDY', 'SHREECEM', 'TATAMTRDVR',\n",
       "       'SBICARD', 'ICICIPRULI', 'TATAMOTORS', 'HCLTECH', 'IRCTC', 'BERGEPAINT',\n",
       "       'DIVISLAB', 'LTI', 'TECHM', 'WIPRO', 'WINPRO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top=resv_12.loc['2022-12-31'].nlargest(50).index\n",
    "tips_filtered = ret_12.reindex(columns = stockRank)\n",
    "tips_filtered\n",
    "ret_12\n",
    "tips_filtered = ret_12.reindex(columns = stockRank)\n",
    "tips_filtered.loc['2022-12-31'].nlargest(100).index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99428707450607"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio=mtl.loc['2022-12-31':,'ANDHRAPAP'][1:2]\n",
    "portfolio.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pf_perfomance(date):\n",
    "    portfolio = mtl.loc[date:,get_top(date)][1:2]\n",
    "    return portfolio.mean(axis=1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2021-04-30         NaN\n",
       "2021-05-31         NaN\n",
       "2021-06-30         NaN\n",
       "2021-07-31         NaN\n",
       "2021-08-31         NaN\n",
       "2021-09-30         NaN\n",
       "2021-10-31         NaN\n",
       "2021-11-30         NaN\n",
       "2021-12-31         NaN\n",
       "2022-01-31         NaN\n",
       "2022-02-28         NaN\n",
       "2022-03-31    1.122700\n",
       "2022-04-30    1.129381\n",
       "2022-05-31    0.878518\n",
       "2022-06-30    0.971378\n",
       "2022-07-31    1.122468\n",
       "2022-08-31    1.081877\n",
       "2022-09-30    0.989608\n",
       "2022-10-31    1.010482\n",
       "2022-11-30    1.090905\n",
       "2022-12-31    1.054834\n",
       "2023-01-31    1.010997\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "returns=[]\n",
    "for date in mtl.index[:-1]:\n",
    "    returns.append(pf_perfomance(date))\n",
    "    \n",
    "pd.Series(returns,index=mtl.index[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in mtl.index[:-1]:\n",
    "    stock_list=get_top(date)\n",
    "    for stock in stock_list:\n",
    "        #fromdate = datetime.strptime(date, '%Y-%m-%d')\n",
    "        todate = datetime.today()\n",
    "        diff=todate-date\n",
    "        timeLine=[[\"1D\",diff.days+1]]#becareful\n",
    "        dataList=getStockData(stock,timeLine)\n",
    "        df=stockFormula.convertToDF(dataList[0][1])\n",
    "\n",
    "        open=df.at[1, 'open']\n",
    "        flag=\"PROGRESS\"\n",
    "        for index, val in df.iterrows():\n",
    "            if index>1 :\n",
    "                if (10000/open)*(val['close']-open)>100: \n",
    "                    flag=\"PASS\"\n",
    "                    print(date,stock,\"pass\")\n",
    "                    break\n",
    "            if index==11:\n",
    "                    flag=\"FAIL\"\n",
    "                    print(date,stock,\"fail\")\n",
    "                    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c1592f3acae157f7e623f1fddfeeda6a695a086981f41b6f646e05a63fb21a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
